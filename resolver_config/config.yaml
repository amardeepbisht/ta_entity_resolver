# resolver_config/config.yaml

# --- Input and Output ---
input:
  path: sample_data/input/restaurants_100.csv #sample_data/input/sample_vendor_data.xlsx
  format: csv  #excel
  sheet_name: Sheet1
  delimiter: ","
  header: true

output:
  fuzzy_matcher_path: output/fuzzy_matcher.csv
  ml_spark_matcher_path: output/ml_spark_matcher.csv
  graph_matcher_path: output/graph_matcher.csv
  resolved_pairs_path: output/final_results.csv
  report_path: output/report_summary.txt
  llm_validated_results_path: output/llm_validated_results.jsonl
  llm_validated_csv_path: output/llm_validated_results.csv
  llm_report_path: output/llm_summary_report.txt
  pipeline_log_path: output/pipeline.log
  
record_id_column: record_id  


# --- Fields to Match ---
# Each field can specify multiple techniques with weights and thresholds
# Prioritize certain fields when computing match score per record pair
fields_to_match:
  - name: name
    weight: 1.0 
    techniques:
      fuzzy: true
    similarity_threshold: 0.8   #per‐field cutoff for accepting a match in the fuzzy matcher
  - name: address
    weight: 1.0 
    techniques:
      fuzzy: true
  - name: city
    weight: 1.0 
    techniques:
      fuzzy: true
  

# --- Matcher Toggle ---   
# Global flags to activate/deactivate specific matchers
matchers:
  use_fuzzy: true
  use_exact: true
  use_normalized: false
  use_phonetic: false
  use_ml_spark_matcher: false
  use_ml_zingg: false
  use_graph: false

# --- Matching Technique Configuration ---
matching_techniques_config:
  string_similarity:
    algorithms:
      levenshtein: true
      jaro_winkler: true
      token_set_ratio: true
    default_threshold: 0.85   #fallback similarity cutoff when a field does not specify its own threshold

  phonetic_similarity:
    # Default algorithm (options: "soundex", "metaphone", "nysiis")
    algorithm: soundex 

  graph_matcher:
    enabled: false  # Set to true to enable Neo4j (requires Neo4j setup)
    neo4j_uri: bolt://3.92.203.172
    neo4j_user: neo4j
    neo4j_password_env_var: NEO4J_PASSWORD
    neo4j_database: neo4j
    entity_columns:
      - name
      - address
      - city
      #- email
    match_types:
      - fuzzy
      - fuzzy
      - fuzzy
    fuzzy_thresholds:
      - 0.7
      - 0.7
      - 1.0


  ml_based_spark_matcher:
    enabled: false
    checkpoint_dir: dbfs:/tmp/spark_matcher_checkpoints/

  ml_based_zingg:
    enabled: false
    model_config: zingg_model.conf


# --- Ensemble Aggregation ---
aggregation_method: weighted_average # Options: "weighted_average", "max_wins", "majority_vote" (majority_vote is more complex)
ensemble_threshold: 0.75    # final score cutoff for determining a match
weights:
  fuzzy_matcher: 0.4
  spark_matcher: 0.3
  graph_matcher: 0.3

# add only if you want advanced logic, if set to false, then fall back to  default
use_advanced_ensemble: false    

#sum of these values should equal weights.fuzzy_matcher; if not, code will log and fallback)
fuzzy_sub_weights:
  levenshtein: 0.13
  jaro_winkler: 0.13
  token_set_ratio: 0.14

# Used if `aggregation_method: majority_vote`, you may specify how many matchers must vote “yes.”
required_votes: 2


#---- Postprocessing ---
postprocessing:
  cluster: false
  canonical_selection: false
  llm_validation: true
  report_generation: true


# --- LLM Configuration ---
# Azure OpenAI Service Configuration
azure_openai:
  # Your deployed model name (corresponds to 'open_ai_engine')
  deployment_name: "gpt-4o-mini"
  
  # Your Azure OpenAI endpoint URL (corresponds to 'open_ai_host')
  endpoint: "https://openai-datafabric-dev-001.openai.azure.com/"
  
  # The environment variable name that holds your API key.
  # It's highly recommended to use an environment variable for the key, not hardcode it here.
  #api_key_env_var: "AZURE_OPENAI_API_KEY"
  api_key_env_var : "AZURE_OPENAI_API_KEY" 
  
  # The API version required for Azure OpenAI.
  api_version: "2024-02-01"
  
  # Optional: Controls the randomness of the LLM's output. 0.0 for deterministic.
  temperature: 0.0
  
  # Optional: Max tokens the LLM can generate in its response.
  max_tokens: 200

# Input file path
input_data:
  # Path to your JSONL input file relative to where the script is run
  file_path: "output/for_llm.jsonl" 


# General LLM validation logic
llm_validation:
  # Validate pairs with a 'final_score' >= this threshold.
  # LLM will only be called for scores between auto_non_match_threshold and auto_match_threshold.
  confidence_threshold_for_llm: 0.70 
  
  # If 'final_score' is very high, consider it a match without LLM call.
  auto_match_threshold: 0.95 
  
  # If 'final_score' is very low, consider it a non-match without LLM call.
  auto_non_match_threshold: 0.2 
  
  # Optional: Log the full raw LLM response content for debugging purposes.
  log_raw_llm_response: false



# --- Data Processing Engine ---
engine: pandas  # default is pandas, keep 'pyspark' for larger datasets


# --- Logging ---
logging_level: "INFO" # DEBUG, INFO, WARNING, ERROR, CRITICAL